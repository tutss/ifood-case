{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9744f3cb-0eec-4614-a10e-9066c6400802",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54a2f8e1-08e4-4dcf-a788-55d137edc768",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dataset = spark.table(\"default.dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7265febb-c1ec-40ac-a2b7-6d9b8fefea11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split day: 21\nTraining set: 72010 rows\nTest set: 14422 rows\n"
     ]
    }
   ],
   "source": [
    "split_day_row = dataset.select(expr(\"percentile_approx(time_since_test_start, 0.8)\").alias(\"split_day\")).collect()\n",
    "split_day = int(split_day_row[0][\"split_day\"])\n",
    "\n",
    "print(f\"Split day: {split_day}\")\n",
    "\n",
    "# Create train and test sets based on time\n",
    "train_data = dataset.filter(col(\"time_since_test_start\") <= split_day)\n",
    "test_data = dataset.filter(col(\"time_since_test_start\") > split_day)\n",
    "\n",
    "print(f\"Training set: {train_data.count()} rows\")\n",
    "print(f\"Test set: {test_data.count()} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b69234c9-7b09-4feb-8117-4546d78d04f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature engineering completed\nNumerical features: 11\nBoolean features: 9\nCategorical features: 2\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spark-031000a9-16c2-4a13-95a8-d8/.ipykernel/2906/command-5448132000915371-1862997173:28: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  X_train[col] = X_train[col].fillna(X_train[col].mean())\n/home/spark-031000a9-16c2-4a13-95a8-d8/.ipykernel/2906/command-5448132000915371-1862997173:29: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  X_test[col] = X_test[col].fillna(X_train[col].mean())  # Use train mean for test\n/home/spark-031000a9-16c2-4a13-95a8-d8/.ipykernel/2906/command-5448132000915371-1862997173:33: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  X_train[col] = X_train[col].fillna('missing')\n/home/spark-031000a9-16c2-4a13-95a8-d8/.ipykernel/2906/command-5448132000915371-1862997173:34: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  X_test[col] = X_test[col].fillna('missing')\n"
     ]
    }
   ],
   "source": [
    "numerical_features = [\n",
    "    'age', 'months_since_register', 'credit_card_limit',\n",
    "    'hist_spent', 'hist_count', 'rolling_spent_30d', 'rolling_count_30d', \n",
    "    'hist_offer_completion_rate', 'discount_value', 'min_value', 'duration'\n",
    "]\n",
    "\n",
    "boolean_features = [\n",
    "    'is_new_customer', 'is_continuous_customer', 'is_tenured_customer', \n",
    "    'is_high_tenured_customer', 'is_extreme_tenured_customer',\n",
    "    'has_email', 'has_mobile', 'has_social', 'has_web'\n",
    "]\n",
    "\n",
    "categorical_features = ['offer_type', 'gender']\n",
    "\n",
    "all_features = numerical_features + boolean_features + categorical_features\n",
    "\n",
    "# Select features and target, convert to pandas\n",
    "train_pandas = train_data.select(all_features + [\"label\"]).toPandas()\n",
    "test_pandas = test_data.select(all_features + [\"label\"]).toPandas()\n",
    "\n",
    "X_train = train_pandas[all_features]\n",
    "y_train = train_pandas[\"label\"]\n",
    "X_test = test_pandas[all_features]\n",
    "y_test = test_pandas[\"label\"]\n",
    "\n",
    "for col in numerical_features:\n",
    "    if col in X_train.columns:\n",
    "        X_train[col] = X_train[col].fillna(X_train[col].mean())\n",
    "        X_test[col] = X_test[col].fillna(X_train[col].mean())  # Use train mean for test\n",
    "\n",
    "for col in categorical_features:\n",
    "    if col in X_train.columns:\n",
    "        X_train[col] = X_train[col].fillna('missing')\n",
    "        X_test[col] = X_test[col].fillna('missing')\n",
    "\n",
    "print(\"Feature engineering completed\")\n",
    "print(f\"Numerical features: {len(numerical_features)}\")\n",
    "print(f\"Boolean features: {len(boolean_features)}\")\n",
    "print(f\"Categorical features: {len(categorical_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef5125c1-a305-4e23-abb4-37d10ba641ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn Pipeline created successfully\nTraining set shape: (72010, 22)\nTest set shape: (14422, 22)\n"
     ]
    }
   ],
   "source": [
    "cat_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "num_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean'))\n",
    "])\n",
    "\n",
    "# Combine transformers\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('cat', cat_transformer, categorical_features),\n",
    "    ('num', num_transformer, numerical_features)\n",
    "], remainder='passthrough')  # This will handle boolean features\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('model', RandomForestClassifier(n_estimators=500, random_state=42))\n",
    "])\n",
    "\n",
    "print(\"sklearn Pipeline created successfully\")\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8be5c40f-25bc-4c2a-960b-995ccb5530ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nNaN values in X_train:\nage                            0\nmonths_since_register          0\ncredit_card_limit              0\nhist_spent                     0\nhist_count                     0\nrolling_spent_30d              0\nrolling_count_30d              0\nhist_offer_completion_rate     0\ndiscount_value                 0\nmin_value                      0\nduration                       0\nis_new_customer                0\nis_continuous_customer         0\nis_tenured_customer            0\nis_high_tenured_customer       0\nis_extreme_tenured_customer    0\nhas_email                      0\nhas_mobile                     0\nhas_social                     0\nhas_web                        0\noffer_type                     0\ngender                         0\ndtype: int64\n\nColumns with NaN values: []\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nNaN values in X_train:\")\n",
    "print(X_train.isnull().sum())\n",
    "print(f\"\\nColumns with NaN values: {X_train.columns[X_train.isnull().any()].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff4a6ce5-3cc1-4fc9-8f24-361071cbe606",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# param_distributions = {\n",
    "#     'model__n_estimators': randint(300, 500),  # Random integers between 50-500\n",
    "#     'model__max_depth': [10, 20, 30, 50, None],  # Discrete choices including None\n",
    "#     'model__min_samples_split': randint(2, 20),  # Random integers between 2-20\n",
    "#     'model__min_samples_leaf': randint(1, 10),  # Random integers between 1-10\n",
    "#     'model__max_features': ['sqrt', 'log2', None],  # Feature sampling strategies\n",
    "# }\n",
    "\n",
    "# n_iter = 20  # Number of random combinations to try\n",
    "# print(\"Starting hyperparameter tuning with RandomizedSearchCV...\")\n",
    "# print(f\"Random parameter combinations to test: {n_iter}\")\n",
    "# print(\"This is more efficient than testing all possible combinations!\")\n",
    "\n",
    "# # Create RandomizedSearchCV object\n",
    "# random_search = RandomizedSearchCV(\n",
    "#     estimator=clf,\n",
    "#     param_distributions=param_distributions,\n",
    "#     n_iter=n_iter,  # Number of random combinations to try\n",
    "#     cv=3,  # 5-fold cross-validation\n",
    "#     scoring='roc_auc',  # Use ROC-AUC as the scoring metric\n",
    "#     n_jobs=-1,  # Use all available cores\n",
    "#     verbose=1,  # Show progress\n",
    "#     random_state=42  # For reproducibility\n",
    "# )\n",
    "\n",
    "# # Fit the random search\n",
    "# print(\"Training models with random hyperparameter combinations...\")\n",
    "# random_search.fit(X_train, y_train)\n",
    "\n",
    "# print(\"Hyperparameter tuning completed!\")\n",
    "# print(f\"Best ROC-AUC score: {random_search.best_score_:.4f}\")\n",
    "# print(\"Best parameters:\")\n",
    "# for param, value in random_search.best_params_.items():\n",
    "#     print(f\"  {param}: {value}\")\n",
    "\n",
    "# # Use the best model for predictions\n",
    "# best_clf = random_search.best_estimator_\n",
    "# print(\"\\nMaking predictions with the best model...\")\n",
    "# y_pred = best_clf.predict(X_test)\n",
    "# y_proba = best_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# print(\"Predictions completed with optimized model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "919aa818-ba2d-45e9-9ceb-7dbb22321d39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# print(f\"Best Cross-Validation ROC-AUC Score: {random_search.best_score_:.4f}\")\n",
    "# print(f\"Best Parameters:\")\n",
    "# for param, value in random_search.best_params_.items():\n",
    "#     print(f\"  {param}: {value}\")\n",
    "\n",
    "# # Show top 5 parameter combinations from random search\n",
    "# results_df = pd.DataFrame(random_search.cv_results_)\n",
    "# top_5 = results_df.nlargest(5, 'mean_test_score')[['params', 'mean_test_score', 'std_test_score']]\n",
    "\n",
    "# print(f\"\\nTop 5 Random Parameter Combinations:\")\n",
    "# for i, (idx, row) in enumerate(top_5.iterrows(), 1):\n",
    "#     print(f\"{i}. Score: {row['mean_test_score']:.4f} (+/- {row['std_test_score']*2:.4f})\")\n",
    "#     print(f\"   Parameters: {row['params']}\")\n",
    "\n",
    "# # Show parameter space coverage\n",
    "# print(f\"\\nRandomized Search Statistics:\")\n",
    "# print(f\"Total combinations tested: {len(results_df)}\")\n",
    "# print(f\"Best score improvement over baseline: {random_search.best_score_ - 0.5:.4f}\")\n",
    "# print(f\"Standard deviation of scores: {results_df['mean_test_score'].std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ea1fd47-98c0-4c35-83b9-e61f31ef6667",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the sklearn model...\nModel training completed\nMaking predictions on test set...\nPredictions completed\n"
     ]
    }
   ],
   "source": [
    "print(\"Training the sklearn model...\")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model training completed\")\n",
    "print(\"Making predictions on test set...\")\n",
    "y_pred = clf.predict(X_test)\n",
    "y_proba = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Predictions completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06410a2c-e303-4cee-bc86-a803bf782b3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n              precision    recall  f1-score   support\n\n           0       0.85      0.75      0.80      7433\n           1       0.76      0.86      0.81      6989\n\n    accuracy                           0.80     14422\n   macro avg       0.81      0.80      0.80     14422\nweighted avg       0.81      0.80      0.80     14422\n\n\nROC AUC Score: 0.8956\n\nConfusion Matrix:\nTrue Negatives: 5584\nFalse Positives: 1849\nFalse Negatives: 997\nTrue Positives: 5992\n\nDetailed Metrics (from sklearn classification_report):\nAccuracy: 0.8027\nClass 0 - Precision: 0.8485, Recall: 0.7512, F1: 0.7969\nClass 1 - Precision: 0.7642, Recall: 0.8573, F1: 0.8081\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report:\")\n",
    "report_text = classification_report(y_test, y_pred)\n",
    "print(report_text)\n",
    "\n",
    "# Extract metrics from classification_report\n",
    "report_dict = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "# Get ROC AUC score\n",
    "auc_score = roc_auc_score(y_test, y_proba)\n",
    "print(f\"\\nROC AUC Score: {auc_score:.4f}\")\n",
    "\n",
    "# Extract metrics for each class from classification_report\n",
    "precision_0 = report_dict['0']['precision']\n",
    "recall_0 = report_dict['0']['recall']\n",
    "f1_0 = report_dict['0']['f1-score']\n",
    "\n",
    "precision_1 = report_dict['1']['precision']\n",
    "recall_1 = report_dict['1']['recall']\n",
    "f1_1 = report_dict['1']['f1-score']\n",
    "\n",
    "accuracy = report_dict['accuracy']\n",
    "\n",
    "# Calculate confusion matrix for display\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(f\"True Negatives: {tn}\")\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"True Positives: {tp}\")\n",
    "\n",
    "print(f\"\\nDetailed Metrics (from sklearn classification_report):\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Class 0 - Precision: {precision_0:.4f}, Recall: {recall_0:.4f}, F1: {f1_0:.4f}\")\n",
    "print(f\"Class 1 - Precision: {precision_1:.4f}, Recall: {recall_1:.4f}, F1: {f1_1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1c206ab-7e6c-4ca4-9d75-e54763775063",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Most Important Features:\n                   feature  importance\n     months_since_register    0.238809\n                       age    0.176240\n         credit_card_limit    0.162147\n            discount_value    0.067997\n                  duration    0.064170\n                 min_value    0.062090\n  offer_type_informational    0.049897\n            gender_missing    0.033020\nhist_offer_completion_rate    0.022688\n           is_new_customer    0.016234\n       is_tenured_customer    0.011884\n                  gender_F    0.011393\n       offer_type_discount    0.011143\n                  gender_M    0.009545\n                has_social    0.009499\n  is_high_tenured_customer    0.008472\n           offer_type_bogo    0.007521\n         rolling_spent_30d    0.007016\n                hist_spent    0.006873\n                   has_web    0.005088\n\nTotal features: 27\nTop 5 features:\n  1. months_since_register: 0.2388\n  2. age: 0.1762\n  3. credit_card_limit: 0.1621\n  4. discount_value: 0.0680\n  5. duration: 0.0642\n"
     ]
    }
   ],
   "source": [
    "# clf = best_clf\n",
    "\n",
    "model = clf.named_steps['model']\n",
    "feature_importances = model.feature_importances_\n",
    "\n",
    "# Get feature names from the preprocessor\n",
    "encoder = clf.named_steps['prep'].named_transformers_['cat']\n",
    "cat_names = encoder.get_feature_names_out(categorical_features)\n",
    "all_feature_names = list(cat_names) + numerical_features + boolean_features\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': all_feature_names,\n",
    "    'importance': feature_importances\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 20 Most Important Features:\")\n",
    "print(importance_df.head(20).to_string(index=False))\n",
    "\n",
    "print(f\"\\nTotal features: {len(all_feature_names)}\")\n",
    "print(f\"Top 5 features:\")\n",
    "for i, (idx, row) in enumerate(importance_df.head(5).iterrows()):\n",
    "    print(f\"  {i+1}. {row['feature']}: {row['importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c9f3972-44c8-4931-9f65-7d5863e8e051",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "metrics_data = []\n",
    "description = \"Hybrid PySpark + sklearn RandomForest with historical, rolling features, tenure segments and credit limit\"\n",
    "features_str = \",\".join(all_features)\n",
    "\n",
    "metrics_rows = [\n",
    "    {\"type\": \"metric\", \"metric\": \"precision\", \"class\": \"0\", \"name\": \"precision_class_0\", \"value\": precision_0},\n",
    "    {\"type\": \"metric\", \"metric\": \"recall\", \"class\": \"0\", \"name\": \"recall_class_0\", \"value\": recall_0},\n",
    "    {\"type\": \"metric\", \"metric\": \"f1-score\", \"class\": \"0\", \"name\": \"f1_class_0\", \"value\": f1_0},\n",
    "    {\"type\": \"metric\", \"metric\": \"precision\", \"class\": \"1\", \"name\": \"precision_class_1\", \"value\": precision_1},\n",
    "    {\"type\": \"metric\", \"metric\": \"recall\", \"class\": \"1\", \"name\": \"recall_class_1\", \"value\": recall_1},\n",
    "    {\"type\": \"metric\", \"metric\": \"f1-score\", \"class\": \"1\", \"name\": \"f1_class_1\", \"value\": f1_1},\n",
    "    {\"type\": \"metric\", \"metric\": \"accuracy\", \"class\": \"\", \"name\": \"accuracy\", \"value\": accuracy},\n",
    "    {\"type\": \"metric\", \"metric\": \"roc_auc\", \"class\": \"\", \"name\": \"roc_auc\", \"value\": auc_score}\n",
    "]\n",
    "\n",
    "for row in metrics_rows:\n",
    "    row.update({\n",
    "        \"model_name\": \"RandomForest\",\n",
    "        \"run_date\": current_time,\n",
    "        \"description\": description,\n",
    "        \"features\": features_str\n",
    "    })\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_rows)\n",
    "\n",
    "importance_export = importance_df.copy()\n",
    "importance_export[\"type\"] = \"feature_importance\"\n",
    "importance_export[\"metric\"] = \"\"\n",
    "importance_export[\"class\"] = \"\"\n",
    "importance_export[\"name\"] = importance_export[\"feature\"]\n",
    "importance_export[\"value\"] = importance_export[\"importance\"]\n",
    "importance_export[\"model_name\"] = \"RandomForest\"\n",
    "importance_export[\"run_date\"] = current_time\n",
    "importance_export[\"description\"] = description\n",
    "importance_export[\"features\"] = features_str\n",
    "\n",
    "importance_export = importance_export[metrics_df.columns]\n",
    "\n",
    "combined_results = pd.concat([metrics_df, importance_export], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d79fb37-fbe1-4f77-a48a-b4e17ab669c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to Databricks table: metrics\nTotal records added: 35\nRecords saved at: 2025-08-13 00:10:45\n"
     ]
    }
   ],
   "source": [
    "combined_results_spark = spark.createDataFrame(combined_results)\n",
    "\n",
    "combined_results_spark.write.mode(\"append\").saveAsTable(\"metrics\")\n",
    "\n",
    "print(f\"Results saved to Databricks table: metrics\")\n",
    "print(f\"Total records added: {len(combined_results)}\")\n",
    "print(f\"Records saved at: {current_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a6724dcb-f6af-4de0-9793-63289df39c69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "modelling",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}